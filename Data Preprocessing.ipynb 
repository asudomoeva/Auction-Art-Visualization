{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T02:42:18.926442Z",
     "start_time": "2018-04-27T02:42:17.527430Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno # pip3 install missingno\n",
    "import seaborn as sns \n",
    "sns.set_style(\"whitegrid\")\n",
    "%matplotlib inline\n",
    "\n",
    "pd.options.display.max_rows = 999\n",
    "pd.options.display.max_columns = 999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T02:42:19.735823Z",
     "start_time": "2018-04-27T02:42:18.928190Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"sothebys.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T02:42:19.827920Z",
     "start_time": "2018-04-27T02:42:19.737510Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convert datatime columns\n",
    "df.start_date =pd.to_datetime(df.start_date)\n",
    "df.end_date =pd.to_datetime(df.end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T02:42:19.850598Z",
     "start_time": "2018-04-27T02:42:19.830646Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check Auction length\n",
    "cnt=np.where(df[\"end_date\"]!=df[\"start_date\"],1,0).sum()\n",
    "#cnt=0\n",
    "df.drop(\"end_date\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, we'll use $start\\_date$ as the time that the auction occured going forward. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T02:42:19.877596Z",
     "start_time": "2018-04-27T02:42:19.852537Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#clean up birth_year\n",
    "df.birth_year=pd.to_numeric(df.birth_year,errors='coerce').astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Add Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T02:42:20.210182Z",
     "start_time": "2018-04-27T02:42:19.879939Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add year, month and season for auction time\n",
    "df[\"auc_date\"] = pd.DatetimeIndex(df.start_date).normalize()\n",
    "df['auc_year'] = pd.DatetimeIndex(df['start_date']).year\n",
    "df['auc_month'] = pd.DatetimeIndex(df['start_date']).month\n",
    "df[\"auc_year_month\"]=df[\"start_date\"].map(lambda x: x.strftime('%Y-%m'))\n",
    "df[\"auc_year_month_date\"]=df[\"start_date\"].map(lambda x: x.strftime('%Y-%m-%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T02:42:20.293320Z",
     "start_time": "2018-04-27T02:42:20.211905Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['auc_season_num'] = df[\"start_date\"].apply(lambda dt: (dt.month%12 + 3)//3)\n",
    "def season(x):\n",
    "    if x==1:\n",
    "        return \"winter\"\n",
    "    elif x==2:\n",
    "        return \"spring\"\n",
    "    elif x==3:\n",
    "        return \"summer\"\n",
    "    else: return \"fall\"\n",
    "df[\"auc_season\"] = df[\"auc_season_num\"].apply(season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T02:42:20.330829Z",
     "start_time": "2018-04-27T02:42:20.295323Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add a boolean column to indicate if the lot is named \"untitled\"\n",
    "words='|'.join([\"INTITULADO\",\"UNTITLED\",\"OHNE TITEL\",\"SANS TITRE\",\"SENZA TITOLO\"])\n",
    "df[\"is_untitled\"]=np.where(df[\"lot_title\"].str.contains(words), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T02:42:21.092961Z",
     "start_time": "2018-04-27T02:42:20.722673Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize \"nth_in_auction\" column by \"auction_id\" into 100 tiles\n",
    "df[\"auc_order\"]= df.groupby(\"auction_id\")[\"nth_in_auction\"].transform(\n",
    "                     lambda x: pd.qcut(x, 100, labels=range(1,101))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T02:42:21.161001Z",
     "start_time": "2018-04-27T02:42:21.125676Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Returns percent_in_auction divided by lot_number = percentage through the auction the lot when lot was shown\n",
    "lot_order_df = df[['nth_in_auction', 'number_of_lots']].copy()\n",
    "df['percent_in_auction'] = np.round(lot_order_df.nth_in_auction / lot_order_df.number_of_lots, 3)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T02:42:21.627390Z",
     "start_time": "2018-04-27T02:42:21.620786Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add avg_estimate\n",
    "df[\"estimate_avg\"]=(df[\"estimate_low\"] + df[\"estimate_high\"])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T02:42:21.966192Z",
     "start_time": "2018-04-27T02:42:21.933155Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add author era\n",
    "import re\n",
    "\n",
    "df[\"auth_era_num\"]= df[\"birth_year\"]//10\n",
    "def tostr(x):\n",
    "    temp=str(x)\n",
    "    temp=temp[:3]+\"0\"\n",
    "    return temp\n",
    "df[\"auth_era\"]=df[\"auth_era_num\"].apply(tostr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Convert Currency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T02:42:22.669296Z",
     "start_time": "2018-04-27T02:42:22.649000Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df[df[\"currency\"].isnull()==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T02:42:35.075574Z",
     "start_time": "2018-04-27T02:42:22.938434Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pip install --user currencyconverter\n",
    "from currency_converter import CurrencyConverter\n",
    "from datetime import datetime\n",
    "c = CurrencyConverter(fallback_on_wrong_date=True, fallback_on_missing_rate=True)\n",
    "\n",
    "hammer_price = df[['hammer_price_bp', 'currency', 'start_date']].copy()\n",
    "est_low = df[['estimate_low', 'currency', 'start_date']].copy()\n",
    "est_high = df[['estimate_high', 'currency', 'start_date']].copy()\n",
    "est_avg = df[['estimate_avg', 'currency', 'start_date']].copy()\n",
    "\n",
    "hammer_price.start_date = hammer_price.start_date.apply(lambda x: x.strftime('%Y-%m-%d') if not pd.isnull(x) else x)\n",
    "est_low.start_date = est_low.start_date.apply(lambda x: x.strftime('%Y-%m-%d') if not pd.isnull(x) else x)\n",
    "est_high.start_date = est_high.start_date.apply(lambda x: x.strftime('%Y-%m-%d') if not pd.isnull(x) else x)\n",
    "est_avg.start_date = est_avg.start_date.apply(lambda x: x.strftime('%Y-%m-%d') if not pd.isnull(x) else x)\n",
    "\n",
    "df['hammer_price_bp_usd'] = hammer_price.apply(lambda x: np.round(c.convert(x[0], x[1], 'USD', date=pd.to_datetime(x[2])), 2) if not pd.isnull(x[1]) else x[0], axis=1)\n",
    "df['estimate_low_usd'] = est_low.apply(lambda x: np.round(c.convert(x[0], x[1], 'USD', date=pd.to_datetime(x[2])), 2) if not pd.isnull(x[1]) else x[0], axis=1)    \n",
    "df['estimate_high_usd'] = est_high.apply(lambda x: np.round(c.convert(x[0], x[1], 'USD', date=pd.to_datetime(x[2])), 2) if not pd.isnull(x[1]) else x[0], axis=1)\n",
    "df['estimate_avg_usd'] = est_avg.apply(lambda x: np.round(c.convert(x[0], x[1], 'USD', date=pd.to_datetime(x[2])), 2) if not pd.isnull(x[1]) else x[0], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Add more features based on the converted price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T02:42:35.085827Z",
     "start_time": "2018-04-27T02:42:35.076912Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add converted Hammer Price Range\n",
    "def price_range(x):\n",
    "    if x <10000:\n",
    "        return \"<$10K\"\n",
    "    elif x<50000:\n",
    "        return \"<$50K\"\n",
    "    elif x <500000:\n",
    "        return \"<$500K\"\n",
    "    elif x is None:\n",
    "        return None\n",
    "    else: return \"$500K+\"\n",
    "df[\"hammer_price_bp_usd_range\"] = df[\"hammer_price_bp_usd\"].apply(price_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Export to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T02:42:36.973812Z",
     "start_time": "2018-04-27T02:42:35.087049Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"final_sothebys.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T02:42:36.980207Z",
     "start_time": "2018-04-27T02:42:36.975375Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average lots per auction:.357.30713970912296\n"
     ]
    }
   ],
   "source": [
    "print(\"average lots per auction:.{}\".format(df.number_of_lots.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 5. Create JSON File for Interactive Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T02:42:37.044290Z",
     "start_time": "2018-04-27T02:42:36.982128Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the columns needed for interactive part\n",
    "interactive_df = df[['lot_id', 'hammer_price_bp_usd', 'location', 'auc_date', 'auc_year', 'external_image_url']].copy()\n",
    "\n",
    "# drop null values (for hammer price)\n",
    "interactive_df.dropna(axis=0, inplace=True)\n",
    "\n",
    "# get hammer price averages by year\n",
    "interactive_df.groupby('auc_year')['hammer_price_bp_usd'].mean().reset_index(name=\"year_avg\")\n",
    "\n",
    "# write to json file\n",
    "interactive_df.to_json('app/interactive.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
